{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Evaluation Plan\n",
    "\n",
    "This notebook is used for developing the training & evaluation steps that will be converted to Kubeflow components.  Since a pre-trained model is being used right now, there is no training, but ordinarily this would be where the training step would go, and if we do decide to fine-tune the model, it could be done here.\n",
    "\n",
    "## Load the Pre-Trained Model from Hugging Face Hub\n",
    "\n",
    "By initializing the model from a name string (all-MiniLM-L6-v2), sentence transformers knows to get the model from [the hub](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pkexec rmmod nvidia_uvm\n",
    "!pkexec modprobe nvidia_uvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import typing as t\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from google.cloud import storage\n",
    "from pathlib import Path\n",
    "from subprocess import call\n",
    "from scipy.spatial.distance import cdist\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import ndcg_score, label_ranking_average_precision_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
    "MODEL = SentenceTransformer(MODEL_NAME, device=DEVICE)\n",
    "\n",
    "if DEVICE == \"cuda\":\n",
    "    torch.cuda.empty_cache()\n",
    "print(\"Using device\", DEVICE)\n",
    "\n",
    "LOCAL_MODEL_PATH = \"local_model\"\n",
    "\n",
    "PROJECT_ID = \"queryable-docs-dev\"\n",
    "REGION = \"us-central1\"\n",
    "GCS_BUCKET = \"queryable-docs-artifacts-5024\"\n",
    "GCS_MODEL_FOLDER = f\"{MODEL_NAME.lower()}\"\n",
    "GCS_MODEL_FOLDER_URI = f\"gs://{GCS_BUCKET}/{GCS_MODEL_FOLDER}\"\n",
    "GCS_PIPELINE_ARTIFACTS_FOLDER = f\"{GCS_BUCKET}/{MODEL_NAME.lower()}/training_and_eval_artifacts\"\n",
    "GCS_PIPELINE_ARTIFACTS_URI = f\"gs://{GCS_PIPELINE_ARTIFACTS_FOLDER}\"\n",
    "\n",
    "LOCAL_DATA_FOLDER = \"data\"\n",
    "GCS_DATA_FOLDER = \"ir_eval_data\"\n",
    "\n",
    "GCS_CLIENT = storage.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tune the Model\n",
    "\n",
    "We are not doing this, so here is a placeholder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Model to GCS\n",
    "\n",
    "If we were fine-tuning, we would want to save the weights.  Let's go through the motions anyway.\n",
    "\n",
    "It would be nice to have a custom model hub, or to be able to save and load models directly to/from cloud storage.  But Hugging Face does not [and will not](https://github.com/huggingface/transformers/issues/23412) support that, so we will locally and then upload to cloud storage.\n",
    "\n",
    "Saving to cloud storage requires iterating over the folder structure with the cloud storage Python API.  gsutil makes this much easier, but it must be called from the shell. Calling shell commands in Jupyter with subprocess is not straightforward, so we will just run commands directly here and make a function for using subprocess when we shift over to kubeflow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model locally first\n",
    "MODEL.save(LOCAL_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./local_model/1_Pooling/config.json [Content-Type=application/json]...\n",
      "Copying file://./local_model/config.json [Content-Type=application/json]...     \n",
      "Copying file://./local_model/config_sentence_transformers.json [Content-Type=application/json]...\n",
      "Copying file://./local_model/modules.json [Content-Type=application/json]...    \n",
      "- [4 files][  1.4 KiB/  1.4 KiB]                                                \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying file://./local_model/pytorch_model.bin [Content-Type=application/octet-stream]...\n",
      "Copying file://./local_model/README.md [Content-Type=text/markdown]...          \n",
      "Copying file://./local_model/sentence_bert_config.json [Content-Type=application/json]...\n",
      "Copying file://./local_model/special_tokens_map.json [Content-Type=application/json]...\n",
      "Copying file://./local_model/tokenizer_config.json [Content-Type=application/json]...\n",
      "Copying file://./local_model/tokenizer.json [Content-Type=application/json]...  \n",
      "Copying file://./local_model/vocab.txt [Content-Type=text/plain]...             \n",
      "\\ [11 files][ 87.6 MiB/ 87.6 MiB]   81.4 KiB/s                                  \n",
      "Operation completed over 11 objects/87.6 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp -r ./local_model/* $GCS_MODEL_FOLDER_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -R local_model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def copy_local_directory_to_gcs(model, local_path: str, bucket_folder_uri: str) -> None:\n",
    "    \"\"\"Use gsutil to copy a directory of files to a GCS bucket folder.\"\"\"\n",
    "    # save the model locally first\n",
    "    model.save(local_path)\n",
    "\n",
    "    # copy files to bucket\n",
    "    call([\"gsutil\", \"cp\", \"-r\", f\"./${local_path}/*\", f\"${bucket_folder_uri}\"], shell=True)\n",
    "\n",
    "    # remove local directory\n",
    "    call([\"rm\", \"-R\", f\"${local_path}\"], shell=True)\n",
    "\n",
    "\n",
    "copy_local_directory_to_gcs(\n",
    "    model=MODEL,\n",
    "    local_path=LOCAL_MODEL_PATH,\n",
    "    bucket_folder_uri=GCS_MODEL_FOLDER_URI\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the bucket must be deleted:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!gsutil rm -R $GCS_MODEL_FOLDER_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model\n",
    "\n",
    "The next part of the pipeline will be the evaluation component, which will need to load the models and the data, and evaluate, and log metrics.\n",
    "\n",
    "### Load the Model from GCS\n",
    "\n",
    "If this notebook has been running from the start, the model will already be in memory.  But we should act as if these were micro-services, and the training service ends after dumping the model to storage.  The evaluation service should then read from storage instead of from memory.  We will do this because when we port this code over to Kubeflow, we will have to do it there.\n",
    "\n",
    "First we will copy the files from cloud storage to a local folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_files_from_cloud_storage(\n",
    "    gcs_client, \n",
    "    bucket: str, \n",
    "    bucket_folder: str, \n",
    "    local_folder: str,\n",
    "    exclude_list: t.List[str] = None\n",
    ") -> None:\n",
    "    \"\"\"Copies files from cloud storage folder to local folder.\"\"\"\n",
    "    bucket = gcs_client.get_bucket(bucket)\n",
    "    blobs = bucket.list_blobs(prefix=bucket_folder)\n",
    "    for blob in blobs:\n",
    "        if blob.name.endswith(\"/\"):\n",
    "            continue\n",
    "        path_split = blob.name.split(\"/\")\n",
    "        filename = path_split[-1]\n",
    "        directory = \"/\".join(path_split[:-1])\n",
    "        if exclude_list is not None and (directory in exclude_list or filename in exclude_list):\n",
    "            print(f\"Skipping artifact {blob.name}\")\n",
    "            next\n",
    "        path = Path(f\"{local_folder}/{directory}\")\n",
    "        path.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"Downloading {blob.name} to: {path}/{filename}\\n\")\n",
    "        blob.download_to_filename(f\"{path}/{filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading all-minilm-l6-v2/1_Pooling/config.json to: local_model/all-minilm-l6-v2/1_Pooling/config.json\n",
      "\n",
      "Downloading all-minilm-l6-v2/README.md to: local_model/all-minilm-l6-v2/README.md\n",
      "\n",
      "Downloading all-minilm-l6-v2/config.json to: local_model/all-minilm-l6-v2/config.json\n",
      "\n",
      "Downloading all-minilm-l6-v2/config_sentence_transformers.json to: local_model/all-minilm-l6-v2/config_sentence_transformers.json\n",
      "\n",
      "Downloading all-minilm-l6-v2/modules.json to: local_model/all-minilm-l6-v2/modules.json\n",
      "\n",
      "Downloading all-minilm-l6-v2/pytorch_model.bin to: local_model/all-minilm-l6-v2/pytorch_model.bin\n",
      "\n",
      "Downloading all-minilm-l6-v2/sentence_bert_config.json to: local_model/all-minilm-l6-v2/sentence_bert_config.json\n",
      "\n",
      "Downloading all-minilm-l6-v2/special_tokens_map.json to: local_model/all-minilm-l6-v2/special_tokens_map.json\n",
      "\n",
      "Downloading all-minilm-l6-v2/tokenizer.json to: local_model/all-minilm-l6-v2/tokenizer.json\n",
      "\n",
      "Downloading all-minilm-l6-v2/tokenizer_config.json to: local_model/all-minilm-l6-v2/tokenizer_config.json\n",
      "\n",
      "Downloading all-minilm-l6-v2/vocab.txt to: local_model/all-minilm-l6-v2/vocab.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "download_files_from_cloud_storage(\n",
    "    gcs_client=GCS_CLIENT, \n",
    "    bucket=GCS_BUCKET, \n",
    "    bucket_folder=GCS_MODEL_FOLDER, \n",
    "    local_folder=LOCAL_MODEL_PATH,\n",
    "    exclude_list=[\"training_and_eval_artifacts\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from local path\n",
    "MODEL = SentenceTransformer(f\"{LOCAL_MODEL_PATH}/{GCS_MODEL_FOLDER}\", device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Eval Data from GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ir_eval_data/corpus.json to: data/ir_eval_data/corpus.json\n",
      "\n",
      "Downloading ir_eval_data/qrels.json to: data/ir_eval_data/qrels.json\n",
      "\n",
      "Downloading ir_eval_data/queries.json to: data/ir_eval_data/queries.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "download_files_from_cloud_storage(\n",
    "    gcs_client=GCS_CLIENT, \n",
    "    bucket=GCS_BUCKET, \n",
    "    bucket_folder=GCS_DATA_FOLDER, \n",
    "    local_folder=LOCAL_DATA_FOLDER\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the eval data from local path\n",
    "with open(f\"{LOCAL_DATA_FOLDER}/{GCS_DATA_FOLDER}/corpus.json\", \"r\") as f:\n",
    "    corpus = json.load(f)\n",
    "with open(f\"{LOCAL_DATA_FOLDER}/{GCS_DATA_FOLDER}/queries.json\", \"r\") as f:\n",
    "    queries = json.load(f)\n",
    "with open(f\"{LOCAL_DATA_FOLDER}/{GCS_DATA_FOLDER}/qrels.json\", \"r\") as f:\n",
    "    qrels = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Inference on Eval Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_model_card_vars': {},\n",
       " '_model_card_text': '---\\npipeline_tag: sentence-similarity\\ntags:\\n- sentence-transformers\\n- feature-extraction\\n- sentence-similarity\\nlanguage: en\\nlicense: apache-2.0\\ndatasets:\\n- s2orc\\n- flax-sentence-embeddings/stackexchange_xml\\n- MS Marco\\n- gooaq\\n- yahoo_answers_topics\\n- code_search_net\\n- search_qa\\n- eli5\\n- snli\\n- multi_nli\\n- wikihow\\n- natural_questions\\n- trivia_qa\\n- embedding-data/sentence-compression\\n- embedding-data/flickr30k-captions\\n- embedding-data/altlex\\n- embedding-data/simple-wiki\\n- embedding-data/QQP\\n- embedding-data/SPECTER\\n- embedding-data/PAQ_pairs\\n- embedding-data/WikiAnswers\\n\\n---\\n\\n\\n# all-MiniLM-L6-v2\\nThis is a [sentence-transformers](https://www.SBERT.net) model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search.\\n\\n## Usage (Sentence-Transformers)\\nUsing this model becomes easy when you have [sentence-transformers](https://www.SBERT.net) installed:\\n\\n```\\npip install -U sentence-transformers\\n```\\n\\nThen you can use the model like this:\\n```python\\nfrom sentence_transformers import SentenceTransformer\\nsentences = [\"This is an example sentence\", \"Each sentence is converted\"]\\n\\nmodel = SentenceTransformer(\\'sentence-transformers/all-MiniLM-L6-v2\\')\\nembeddings = model.encode(sentences)\\nprint(embeddings)\\n```\\n\\n## Usage (HuggingFace Transformers)\\nWithout [sentence-transformers](https://www.SBERT.net), you can use the model like this: First, you pass your input through the transformer model, then you have to apply the right pooling-operation on-top of the contextualized word embeddings.\\n\\n```python\\nfrom transformers import AutoTokenizer, AutoModel\\nimport torch\\nimport torch.nn.functional as F\\n\\n#Mean Pooling - Take attention mask into account for correct averaging\\ndef mean_pooling(model_output, attention_mask):\\n    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\\n    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\\n    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\\n\\n\\n# Sentences we want sentence embeddings for\\nsentences = [\\'This is an example sentence\\', \\'Each sentence is converted\\']\\n\\n# Load model from HuggingFace Hub\\ntokenizer = AutoTokenizer.from_pretrained(\\'sentence-transformers/all-MiniLM-L6-v2\\')\\nmodel = AutoModel.from_pretrained(\\'sentence-transformers/all-MiniLM-L6-v2\\')\\n\\n# Tokenize sentences\\nencoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors=\\'pt\\')\\n\\n# Compute token embeddings\\nwith torch.no_grad():\\n    model_output = model(**encoded_input)\\n\\n# Perform pooling\\nsentence_embeddings = mean_pooling(model_output, encoded_input[\\'attention_mask\\'])\\n\\n# Normalize embeddings\\nsentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\\n\\nprint(\"Sentence embeddings:\")\\nprint(sentence_embeddings)\\n```\\n\\n## Evaluation Results\\n\\nFor an automated evaluation of this model, see the *Sentence Embeddings Benchmark*: [https://seb.sbert.net](https://seb.sbert.net?model_name=sentence-transformers/all-MiniLM-L6-v2)\\n\\n------\\n\\n## Background\\n\\nThe project aims to train sentence embedding models on very large sentence level datasets using a self-supervised \\ncontrastive learning objective. We used the pretrained [`nreimers/MiniLM-L6-H384-uncased`](https://huggingface.co/nreimers/MiniLM-L6-H384-uncased) model and fine-tuned in on a \\n1B sentence pairs dataset. We use a contrastive learning objective: given a sentence from the pair, the model should predict which out of a set of randomly sampled other sentences, was actually paired with it in our dataset.\\n\\nWe developped this model during the \\n[Community week using JAX/Flax for NLP & CV](https://discuss.huggingface.co/t/open-to-the-community-community-week-using-jax-flax-for-nlp-cv/7104), \\norganized by Hugging Face. We developped this model as part of the project:\\n[Train the Best Sentence Embedding Model Ever with 1B Training Pairs](https://discuss.huggingface.co/t/train-the-best-sentence-embedding-model-ever-with-1b-training-pairs/7354). We benefited from efficient hardware infrastructure to run the project: 7 TPUs v3-8, as well as intervention from Googles Flax, JAX, and Cloud team member about efficient deep learning frameworks.\\n\\n## Intended uses\\n\\nOur model is intented to be used as a sentence and short paragraph encoder. Given an input text, it ouptuts a vector which captures \\nthe semantic information. The sentence vector may be used for information retrieval, clustering or sentence similarity tasks.\\n\\nBy default, input text longer than 256 word pieces is truncated.\\n\\n\\n## Training procedure\\n\\n### Pre-training \\n\\nWe use the pretrained [`nreimers/MiniLM-L6-H384-uncased`](https://huggingface.co/nreimers/MiniLM-L6-H384-uncased) model. Please refer to the model card for more detailed information about the pre-training procedure.\\n\\n### Fine-tuning \\n\\nWe fine-tune the model using a contrastive objective. Formally, we compute the cosine similarity from each possible sentence pairs from the batch.\\nWe then apply the cross entropy loss by comparing with true pairs.\\n\\n#### Hyper parameters\\n\\nWe trained ou model on a TPU v3-8. We train the model during 100k steps using a batch size of 1024 (128 per TPU core).\\nWe use a learning rate warm up of 500. The sequence length was limited to 128 tokens. We used the AdamW optimizer with\\na 2e-5 learning rate. The full training script is accessible in this current repository: `train_script.py`.\\n\\n#### Training data\\n\\nWe use the concatenation from multiple datasets to fine-tune our model. The total number of sentence pairs is above 1 billion sentences.\\nWe sampled each dataset given a weighted probability which configuration is detailed in the `data_config.json` file.\\n\\n\\n| Dataset                                                  | Paper                                    | Number of training tuples  |\\n|--------------------------------------------------------|:----------------------------------------:|:--------------------------:|\\n| [Reddit comments (2015-2018)](https://github.com/PolyAI-LDN/conversational-datasets/tree/master/reddit) | [paper](https://arxiv.org/abs/1904.06472) | 726,484,430 |\\n| [S2ORC](https://github.com/allenai/s2orc) Citation pairs (Abstracts) | [paper](https://aclanthology.org/2020.acl-main.447/) | 116,288,806 |\\n| [WikiAnswers](https://github.com/afader/oqa#wikianswers-corpus) Duplicate question pairs | [paper](https://doi.org/10.1145/2623330.2623677) | 77,427,422 |\\n| [PAQ](https://github.com/facebookresearch/PAQ) (Question, Answer) pairs | [paper](https://arxiv.org/abs/2102.07033) | 64,371,441 |\\n| [S2ORC](https://github.com/allenai/s2orc) Citation pairs (Titles) | [paper](https://aclanthology.org/2020.acl-main.447/) | 52,603,982 |\\n| [S2ORC](https://github.com/allenai/s2orc) (Title, Abstract) | [paper](https://aclanthology.org/2020.acl-main.447/) | 41,769,185 |\\n| [Stack Exchange](https://huggingface.co/datasets/flax-sentence-embeddings/stackexchange_xml) (Title, Body) pairs  | - | 25,316,456 |\\n| [Stack Exchange](https://huggingface.co/datasets/flax-sentence-embeddings/stackexchange_xml) (Title+Body, Answer) pairs  | - | 21,396,559 |\\n| [Stack Exchange](https://huggingface.co/datasets/flax-sentence-embeddings/stackexchange_xml) (Title, Answer) pairs  | - | 21,396,559 |\\n| [MS MARCO](https://microsoft.github.io/msmarco/) triplets | [paper](https://doi.org/10.1145/3404835.3462804) | 9,144,553 |\\n| [GOOAQ: Open Question Answering with Diverse Answer Types](https://github.com/allenai/gooaq) | [paper](https://arxiv.org/pdf/2104.08727.pdf) | 3,012,496 |\\n| [Yahoo Answers](https://www.kaggle.com/soumikrakshit/yahoo-answers-dataset) (Title, Answer) | [paper](https://proceedings.neurips.cc/paper/2015/hash/250cf8b51c773f3f8dc8b4be867a9a02-Abstract.html) | 1,198,260 |\\n| [Code Search](https://huggingface.co/datasets/code_search_net) | - | 1,151,414 |\\n| [COCO](https://cocodataset.org/#home) Image captions | [paper](https://link.springer.com/chapter/10.1007%2F978-3-319-10602-1_48) | 828,395|\\n| [SPECTER](https://github.com/allenai/specter) citation triplets | [paper](https://doi.org/10.18653/v1/2020.acl-main.207) | 684,100 |\\n| [Yahoo Answers](https://www.kaggle.com/soumikrakshit/yahoo-answers-dataset) (Question, Answer) | [paper](https://proceedings.neurips.cc/paper/2015/hash/250cf8b51c773f3f8dc8b4be867a9a02-Abstract.html) | 681,164 |\\n| [Yahoo Answers](https://www.kaggle.com/soumikrakshit/yahoo-answers-dataset) (Title, Question) | [paper](https://proceedings.neurips.cc/paper/2015/hash/250cf8b51c773f3f8dc8b4be867a9a02-Abstract.html) | 659,896 |\\n| [SearchQA](https://huggingface.co/datasets/search_qa) | [paper](https://arxiv.org/abs/1704.05179) | 582,261 |\\n| [Eli5](https://huggingface.co/datasets/eli5) | [paper](https://doi.org/10.18653/v1/p19-1346) | 325,475 |\\n| [Flickr 30k](https://shannon.cs.illinois.edu/DenotationGraph/) | [paper](https://transacl.org/ojs/index.php/tacl/article/view/229/33) | 317,695 |\\n| [Stack Exchange](https://huggingface.co/datasets/flax-sentence-embeddings/stackexchange_xml) Duplicate questions (titles) | | 304,525 |\\n| AllNLI ([SNLI](https://nlp.stanford.edu/projects/snli/) and [MultiNLI](https://cims.nyu.edu/~sbowman/multinli/) | [paper SNLI](https://doi.org/10.18653/v1/d15-1075), [paper MultiNLI](https://doi.org/10.18653/v1/n18-1101) | 277,230 | \\n| [Stack Exchange](https://huggingface.co/datasets/flax-sentence-embeddings/stackexchange_xml) Duplicate questions (bodies) | | 250,519 |\\n| [Stack Exchange](https://huggingface.co/datasets/flax-sentence-embeddings/stackexchange_xml) Duplicate questions (titles+bodies) | | 250,460 |\\n| [Sentence Compression](https://github.com/google-research-datasets/sentence-compression) | [paper](https://www.aclweb.org/anthology/D13-1155/) | 180,000 |\\n| [Wikihow](https://github.com/pvl/wikihow_pairs_dataset) | [paper](https://arxiv.org/abs/1810.09305) | 128,542 |\\n| [Altlex](https://github.com/chridey/altlex/) | [paper](https://aclanthology.org/P16-1135.pdf) | 112,696 |\\n| [Quora Question Triplets](https://quoradata.quora.com/First-Quora-Dataset-Release-Question-Pairs) | - | 103,663 |\\n| [Simple Wikipedia](https://cs.pomona.edu/~dkauchak/simplification/) | [paper](https://www.aclweb.org/anthology/P11-2117/) | 102,225 |\\n| [Natural Questions (NQ)](https://ai.google.com/research/NaturalQuestions) | [paper](https://transacl.org/ojs/index.php/tacl/article/view/1455) | 100,231 |\\n| [SQuAD2.0](https://rajpurkar.github.io/SQuAD-explorer/) | [paper](https://aclanthology.org/P18-2124.pdf) | 87,599 |\\n| [TriviaQA](https://huggingface.co/datasets/trivia_qa) | - | 73,346 |\\n| **Total** | | **1,170,060,424** |',\n",
       " '_model_config': {'__version__': {'sentence_transformers': '2.0.0',\n",
       "   'transformers': '4.6.1',\n",
       "   'pytorch': '1.8.1'}},\n",
       " 'training': True,\n",
       " '_parameters': OrderedDict(),\n",
       " '_buffers': OrderedDict(),\n",
       " '_non_persistent_buffers_set': set(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_is_full_backward_hook': None,\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_post_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict([('0',\n",
       "               Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel ),\n",
       "              ('1',\n",
       "               Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False})),\n",
       "              ('2', Normalize())]),\n",
       " '_target_device': device(type='cuda')}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(model, model_embed_dim: int, queries: dict, corpus: dict) -> t.Tuple[np.array]:\n",
    "    \"\"\"Creates embeddings for the query strings and texts\"\"\"\n",
    "    q_embeddings = np.array(\n",
    "        model.encode(list(queries.values())),\n",
    "        dtype=np.float32\n",
    "    ).reshape(-1, model_embed_dim)\n",
    "\n",
    "    docs = [doc['text'] for doc in corpus.values()]\n",
    "    d_embeddings = np.array(\n",
    "        model.encode(docs),\n",
    "        dtype=np.float32\n",
    "    ).reshape(-1, model_embed_dim)\n",
    "\n",
    "    return q_embeddings, d_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_embed, d_embed = create_embeddings(model=MODEL, model_embed_dim=384, queries=queries, corpus=corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 384) (40724, 384)\n"
     ]
    }
   ],
   "source": [
    "print(q_embed.shape, d_embed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale(d: float, dampening_factor: float = 1):\n",
    "    \"\"\"\n",
    "    Inverts distance to be similarity.  Dividing by d + 1 ensures that 0 becomes 1 in the new scale.\n",
    "\n",
    "    :param d: distance measurement\n",
    "    :param dampening_factor: Increase this to flatten the curve and make larger values fall off slower \n",
    "        in the new scale.  This parameter should be tuned to what makes sense.  1.5 is a reasonable \n",
    "        starting value, see: https://www.desmos.com/calculator/eluirxagoz\n",
    "    \"\"\"\n",
    "    return (1 / (d + 1)) ** (1 / dampening_factor)\n",
    "\n",
    "\n",
    "def determine_clusters(dist_matrix: np.array, dist_threshold: float, text_ids: list = None):\n",
    "    \"\"\"\n",
    "    Builds clusters of similar documents.\n",
    "\n",
    "    :param text_ids: text IDs of documents to cluster, NOT the doc IDs\n",
    "    :param dist_matrix: Pre-computed distance matrix between all docs\n",
    "    :param dist_threshold: Documents with a Euclidean distance > this value are not clustered together.\n",
    "\n",
    "    :return: tuple of number of clusters and dict mapping of doc_id to cluster\n",
    "    \"\"\"\n",
    "    ag = AgglomerativeClustering(\n",
    "        n_clusters=None,\n",
    "        metric='precomputed',\n",
    "        linkage='average',\n",
    "        distance_threshold=dist_threshold\n",
    "    )\n",
    "    clusters = ag.fit_predict(dist_matrix)\n",
    "    if text_ids is not None:\n",
    "        clusters = {id: clusters[i] for i, id in enumerate(text_ids)}\n",
    "    else:\n",
    "        clusters = {id: clusters[i] for i, id in enumerate(range(len(clusters)))}\n",
    "    return ag.n_clusters_, clusters\n",
    "\n",
    "\n",
    "def compute_pairwise_dist_matrix(doc_embeddings: np.array):\n",
    "    \"\"\"Computes pairwise distance matrix for document clustering.\"\"\"\n",
    "    return cdist(doc_embeddings, doc_embeddings, metric='euclidean')\n",
    "\n",
    "\n",
    "def score_relevance(query_vector: np.array, doc_embeddings: np.array, text_ids: list = None):\n",
    "    \"\"\"Computes scaled similarity (relevance) to a query vector for every document.\"\"\"\n",
    "    dist_to_query = cdist(query_vector.reshape(1, -1), doc_embeddings, metric='euclidean')\n",
    "    dist_to_query = rescale(d=dist_to_query[0])\n",
    "    if text_ids is not None:\n",
    "        output = {text_ids[i]: dist_to_query[i] for i in range(len(text_ids))}\n",
    "    else:\n",
    "        output = {i: dist_to_query[i] for i in range(len(dist_to_query))}\n",
    "    return output\n",
    "\n",
    "\n",
    "def combine_labels_and_preds(qrels: dict, qrels_pred: dict, queries: dict, docs: dict) -> pd.DataFrame:\n",
    "    # assemble the labeled data\n",
    "    dfs = []\n",
    "    for q, q_res in qrels.items():\n",
    "        doc_ids = list(q_res)\n",
    "        labels = list(q_res.values())\n",
    "        q_name = [q] * len(doc_ids)\n",
    "        q_text = queries[q]\n",
    "        doc_texts = [docs[did]['text'] for did in doc_ids]\n",
    "        qdf = pd.DataFrame({\n",
    "            \"query\": q_name,\n",
    "            \"query_text\": q_text,\n",
    "            \"doc_id\": doc_ids,\n",
    "            \"doc_text\": doc_texts,\n",
    "            \"label\": labels,\n",
    "        })\n",
    "        qdf = qdf.sort_values([\"label\", \"doc_id\"], ascending=False).reset_index(drop=True)\n",
    "        qdf['binary_label'] = np.where(qdf['label'] > 0, 1, 0)\n",
    "        dfs.append(qdf)\n",
    "    df = pd.concat(dfs, axis=0)\n",
    "\n",
    "    # assemble the predictions\n",
    "    pred_dfs = []\n",
    "    for q, q_res in qrels_pred.items():\n",
    "        doc_ids = list(q_res)\n",
    "        scores = list(q_res.values())\n",
    "        q_name = [q] * len(doc_ids)\n",
    "        pdf = pd.DataFrame({\"query\": q_name, \"doc_id\": doc_ids, \"similarity_score\": scores})\n",
    "        pred_dfs.append(pdf)\n",
    "    pred_df = pd.concat(pred_dfs, axis=0)\n",
    "\n",
    "    # combine the predictions with the labels\n",
    "    final_df = pd.merge(left=df, right=pred_df, how='left', on=['query', 'doc_id'])\n",
    "    final_df['similarity_score'].fillna(0, inplace=True)\n",
    "    final_df.sort_values([\"label\", \"similarity_score\"], ascending=False, inplace=True)\n",
    "    final_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map document IDs from the corpus to their index values in the corpus\n",
    "doc_id_to_tid_map = {k: v for v, k in enumerate(list(corpus))}\n",
    "tid_to_doc_id_map = {k: v for k, v in enumerate(list(corpus))}\n",
    "\n",
    "# map query IDs from the queries to their index values\n",
    "query_index_to_query_id_map = {k: v for v, k in enumerate(list(queries))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map query IDs to their embeddings\n",
    "query_id_to_embed_map = {qid: q_embed[i,:] for i, qid in enumerate(list(queries))}\n",
    "\n",
    "# map document IDs to their embeddings\n",
    "doc_id_to_embedding_map = {did: d_embed[i,:] for i, did in enumerate(list(corpus))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:00<00:00, 3997.49it/s]\n"
     ]
    }
   ],
   "source": [
    "qrels_pred = {}\n",
    "for query_id, doc_ids in tqdm(qrels.items()):\n",
    "    # get the query embedding\n",
    "    qe = query_id_to_embed_map[query_id].reshape(1, -1)\n",
    "    \n",
    "    # get the document embeddings for the docs found in this query's relations\n",
    "    text_ids = [doc_id_to_tid_map[did] for did in list(doc_ids)]\n",
    "    de = np.concatenate([doc_id_to_embedding_map[did] for did in list(doc_ids)], axis=0).reshape(-1, 384)\n",
    " \n",
    "    # score the documents and map scores back to original doc IDs\n",
    "    query_doc_scores = score_relevance(query_vector=qe, doc_embeddings=de, text_ids=text_ids)\n",
    "    query_doc_scores = {tid_to_doc_id_map[k]: v for k, v in query_doc_scores.items()}\n",
    "    \n",
    "    # store results for this query\n",
    "    q_res = {query_id: query_doc_scores}\n",
    "    qrels_pred.update(q_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_labels_and_preds(qrels: dict, qrels_pred: dict, queries: dict, docs: dict) -> pd.DataFrame:\n",
    "    # assemble the labeled data\n",
    "    dfs = []\n",
    "    for q, q_res in qrels.items():\n",
    "        doc_ids = list(q_res)\n",
    "        labels = list(q_res.values())\n",
    "        q_name = [q] * len(doc_ids)\n",
    "        q_text = queries[q]\n",
    "        doc_texts = [docs[did]['text'] for did in doc_ids]\n",
    "        qdf = pd.DataFrame({\n",
    "            \"query\": q_name,\n",
    "            \"query_text\": q_text,\n",
    "            \"doc_id\": doc_ids,\n",
    "            \"doc_text\": doc_texts,\n",
    "            \"label\": labels,\n",
    "        })\n",
    "        qdf = qdf.sort_values([\"label\", \"doc_id\"], ascending=False).reset_index(drop=True)\n",
    "        qdf['binary_label'] = np.where(qdf['label'] > 0, 1, 0)\n",
    "        dfs.append(qdf)\n",
    "    df = pd.concat(dfs, axis=0)\n",
    "\n",
    "    # assemble the predictions\n",
    "    pred_dfs = []\n",
    "    for q, q_res in qrels_pred.items():\n",
    "        doc_ids = list(q_res)\n",
    "        scores = list(q_res.values())\n",
    "        q_name = [q] * len(doc_ids)\n",
    "        pdf = pd.DataFrame({\"query\": q_name, \"doc_id\": doc_ids, \"similarity_score\": scores})\n",
    "        pred_dfs.append(pdf)\n",
    "    pred_df = pd.concat(pred_dfs, axis=0)\n",
    "\n",
    "    # combine the predictions with the labels\n",
    "    final_df = pd.merge(left=df, right=pred_df, how='left', on=['query', 'doc_id'])\n",
    "    final_df['similarity_score'].fillna(0, inplace=True)\n",
    "    final_df.sort_values([\"query\", \"label\", \"similarity_score\"], ascending=False, inplace=True)\n",
    "    final_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return final_df\n",
    "\n",
    "\n",
    "def score_results(df: pd.DataFrame):\n",
    "    \"\"\"Split data into groups, score each query group's ranking by similarity score, and re-combine.\"\"\"\n",
    "    groups = [y for x, y in df.groupby('query')]\n",
    "    for g in range(len(groups)):\n",
    "        groups[g]['ndcg_top10'] = ndcg_score([groups[g]['label']], [groups[g]['similarity_score']], k=10)\n",
    "        groups[g]['ndcg_top100'] = ndcg_score([groups[g]['label']], [groups[g]['similarity_score']], k=100)\n",
    "        groups[g]['ndcg'] = ndcg_score([groups[g]['label']], [groups[g]['similarity_score']])\n",
    "        groups[g]['lrap'] = label_ranking_average_precision_score(\n",
    "            [groups[g]['binary_label']], [groups[g]['similarity_score']]\n",
    "        )\n",
    "        groups[g]['roc_auc'] = roc_auc_score(groups[g]['binary_label'], groups[g]['similarity_score'])\n",
    "    return pd.concat(groups, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>query_text</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>doc_text</th>\n",
       "      <th>label</th>\n",
       "      <th>binary_label</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TREC_Entity-9</td>\n",
       "      <td>Members of The Beaux Arts Trio.</td>\n",
       "      <td>&lt;dbpedia:Bernard_Greenhouse&gt;</td>\n",
       "      <td>Bernard Greenhouse (January 3, 1916 – May 13, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.525035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TREC_Entity-9</td>\n",
       "      <td>Members of The Beaux Arts Trio.</td>\n",
       "      <td>&lt;dbpedia:Antônio_Meneses&gt;</td>\n",
       "      <td>Antônio Meneses Neto (born in Recife, 1957) is...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.441961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TREC_Entity-9</td>\n",
       "      <td>Members of The Beaux Arts Trio.</td>\n",
       "      <td>&lt;dbpedia:Menahem_Pressler&gt;</td>\n",
       "      <td>Menahem Pressler (born 16 December 1923, Magde...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.436024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TREC_Entity-9</td>\n",
       "      <td>Members of The Beaux Arts Trio.</td>\n",
       "      <td>&lt;dbpedia:Ida_Kavafian&gt;</td>\n",
       "      <td>Ida Kavafian (born October 29, 1952, Istanbul)...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.433822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TREC_Entity-9</td>\n",
       "      <td>Members of The Beaux Arts Trio.</td>\n",
       "      <td>&lt;dbpedia:Beaux_Arts_Trio&gt;</td>\n",
       "      <td>The Beaux Arts Trio was a noted piano trio. Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.535366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           query                       query_text  \\\n",
       "0  TREC_Entity-9  Members of The Beaux Arts Trio.   \n",
       "1  TREC_Entity-9  Members of The Beaux Arts Trio.   \n",
       "2  TREC_Entity-9  Members of The Beaux Arts Trio.   \n",
       "3  TREC_Entity-9  Members of The Beaux Arts Trio.   \n",
       "4  TREC_Entity-9  Members of The Beaux Arts Trio.   \n",
       "\n",
       "                         doc_id  \\\n",
       "0  <dbpedia:Bernard_Greenhouse>   \n",
       "1     <dbpedia:Antônio_Meneses>   \n",
       "2    <dbpedia:Menahem_Pressler>   \n",
       "3        <dbpedia:Ida_Kavafian>   \n",
       "4     <dbpedia:Beaux_Arts_Trio>   \n",
       "\n",
       "                                            doc_text  label  binary_label  \\\n",
       "0  Bernard Greenhouse (January 3, 1916 – May 13, ...      2             1   \n",
       "1  Antônio Meneses Neto (born in Recife, 1957) is...      2             1   \n",
       "2  Menahem Pressler (born 16 December 1923, Magde...      2             1   \n",
       "3  Ida Kavafian (born October 29, 1952, Istanbul)...      2             1   \n",
       "4  The Beaux Arts Trio was a noted piano trio. Th...      1             1   \n",
       "\n",
       "   similarity_score  \n",
       "0          0.525035  \n",
       "1          0.441961  \n",
       "2          0.436024  \n",
       "3          0.433822  \n",
       "4          0.535366  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred = combine_labels_and_preds(\n",
    "    qrels=qrels, \n",
    "    qrels_pred=qrels_pred, \n",
    "    queries=queries, \n",
    "    docs=corpus\n",
    ")\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure every query:doc pair has been accounted for\n",
    "assert(len(df_pred) == sum([len(v) for v in qrels.values()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>query_text</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>doc_text</th>\n",
       "      <th>label</th>\n",
       "      <th>binary_label</th>\n",
       "      <th>similarity_score</th>\n",
       "      <th>ndcg_top10</th>\n",
       "      <th>ndcg_top100</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>lrap</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43384</th>\n",
       "      <td>INEX_LD-2009022</td>\n",
       "      <td>Szechwan dish food cuisine</td>\n",
       "      <td>&lt;dbpedia:Suanla_chaoshou&gt;</td>\n",
       "      <td>Suanla chaoshou is a dish of Szechuan cuisine ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.472756</td>\n",
       "      <td>0.194122</td>\n",
       "      <td>0.492381</td>\n",
       "      <td>0.599473</td>\n",
       "      <td>0.281605</td>\n",
       "      <td>0.449405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43385</th>\n",
       "      <td>INEX_LD-2009022</td>\n",
       "      <td>Szechwan dish food cuisine</td>\n",
       "      <td>&lt;dbpedia:Hot_pot&gt;</td>\n",
       "      <td>Hot pot (also known as steamboat in Singapore,...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.470632</td>\n",
       "      <td>0.194122</td>\n",
       "      <td>0.492381</td>\n",
       "      <td>0.599473</td>\n",
       "      <td>0.281605</td>\n",
       "      <td>0.449405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43386</th>\n",
       "      <td>INEX_LD-2009022</td>\n",
       "      <td>Szechwan dish food cuisine</td>\n",
       "      <td>&lt;dbpedia:Chinese_cuisine&gt;</td>\n",
       "      <td>Chinese cuisine includes styles originating fr...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.469359</td>\n",
       "      <td>0.194122</td>\n",
       "      <td>0.492381</td>\n",
       "      <td>0.599473</td>\n",
       "      <td>0.281605</td>\n",
       "      <td>0.449405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43387</th>\n",
       "      <td>INEX_LD-2009022</td>\n",
       "      <td>Szechwan dish food cuisine</td>\n",
       "      <td>&lt;dbpedia:Shuizhu&gt;</td>\n",
       "      <td>Shuizhuroupian (Chinese: 水煮肉片; pinyin: shǔizhǔ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.466894</td>\n",
       "      <td>0.194122</td>\n",
       "      <td>0.492381</td>\n",
       "      <td>0.599473</td>\n",
       "      <td>0.281605</td>\n",
       "      <td>0.449405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43388</th>\n",
       "      <td>INEX_LD-2009022</td>\n",
       "      <td>Szechwan dish food cuisine</td>\n",
       "      <td>&lt;dbpedia:Guoba&gt;</td>\n",
       "      <td>Guoba (鍋耙, 鍋巴, 锅巴, lit. \"pan adherents\"), some...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.466193</td>\n",
       "      <td>0.194122</td>\n",
       "      <td>0.492381</td>\n",
       "      <td>0.599473</td>\n",
       "      <td>0.281605</td>\n",
       "      <td>0.449405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 query                  query_text                     doc_id  \\\n",
       "43384  INEX_LD-2009022  Szechwan dish food cuisine  <dbpedia:Suanla_chaoshou>   \n",
       "43385  INEX_LD-2009022  Szechwan dish food cuisine          <dbpedia:Hot_pot>   \n",
       "43386  INEX_LD-2009022  Szechwan dish food cuisine  <dbpedia:Chinese_cuisine>   \n",
       "43387  INEX_LD-2009022  Szechwan dish food cuisine          <dbpedia:Shuizhu>   \n",
       "43388  INEX_LD-2009022  Szechwan dish food cuisine            <dbpedia:Guoba>   \n",
       "\n",
       "                                                doc_text  label  binary_label  \\\n",
       "43384  Suanla chaoshou is a dish of Szechuan cuisine ...      2             1   \n",
       "43385  Hot pot (also known as steamboat in Singapore,...      2             1   \n",
       "43386  Chinese cuisine includes styles originating fr...      2             1   \n",
       "43387  Shuizhuroupian (Chinese: 水煮肉片; pinyin: shǔizhǔ...      2             1   \n",
       "43388  Guoba (鍋耙, 鍋巴, 锅巴, lit. \"pan adherents\"), some...      2             1   \n",
       "\n",
       "       similarity_score  ndcg_top10  ndcg_top100      ndcg      lrap   roc_auc  \n",
       "43384          0.472756    0.194122     0.492381  0.599473  0.281605  0.449405  \n",
       "43385          0.470632    0.194122     0.492381  0.599473  0.281605  0.449405  \n",
       "43386          0.469359    0.194122     0.492381  0.599473  0.281605  0.449405  \n",
       "43387          0.466894    0.194122     0.492381  0.599473  0.281605  0.449405  \n",
       "43388          0.466193    0.194122     0.492381  0.599473  0.281605  0.449405  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = score_results(df=df_pred)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run check again\n",
    "assert(len(df) == sum([len(v) for v in qrels.values()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param: queries 400\n",
      "Param: documents 40724\n",
      "Param: index_type flat\n",
      "Metric: average_ndcg_top10 0.5132412198580375\n",
      "Metric: average_ndcg_top100 0.6964808780625574\n",
      "Metric: average_ndcg 0.7559563294596426\n",
      "Metric: average_lrap 0.5947266872653154\n",
      "Metric: average_roc_auc 0.7467223131260317\n"
     ]
    }
   ],
   "source": [
    "# parameters and metrics to be logged\n",
    "print(\"Param: queries\", len(queries))\n",
    "print(\"Param: documents\", len(corpus))\n",
    "print(\"Param: index_type\", \"flat\")\n",
    "print(\"Metric: average_ndcg_top10\", df[\"ndcg_top10\"].mean())\n",
    "print(\"Metric: average_ndcg_top100\", df[\"ndcg_top100\"].mean())\n",
    "print(\"Metric: average_ndcg\", df[\"ndcg\"].mean())\n",
    "print(\"Metric: average_lrap\", df[\"lrap\"].mean())\n",
    "print(\"Metric: average_roc_auc\", df[\"roc_auc\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6216015288176907\n",
      "0.48863184132554155\n",
      "0.5221475182606636\n"
     ]
    }
   ],
   "source": [
    "# check some categories\n",
    "# baselines here: https://github.com/iai-group/DBpedia-Entity/\n",
    "print(df[df['query'].str.contains(\"SemSearch_ES\")]['ndcg_top10'].mean())\n",
    "print(df[df['query'].str.contains(\"INEX_LD\")]['ndcg_top10'].mean())\n",
    "print(df[df['query'].str.contains(\"QALD2\")]['ndcg_top10'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['INEX_LD-20120111',\n",
       " 'INEX_LD-20120121',\n",
       " 'INEX_LD-20120122',\n",
       " 'INEX_LD-20120131',\n",
       " 'INEX_LD-20120211',\n",
       " 'INEX_LD-20120221',\n",
       " 'INEX_LD-20120231',\n",
       " 'INEX_LD-20120232',\n",
       " 'INEX_LD-20120311',\n",
       " 'INEX_LD-20120312',\n",
       " 'INEX_LD-20120321',\n",
       " 'INEX_LD-20120331',\n",
       " 'INEX_LD-20120332',\n",
       " 'INEX_LD-20120411',\n",
       " 'INEX_LD-20120412',\n",
       " 'INEX_LD-20120421',\n",
       " 'INEX_LD-20120422',\n",
       " 'INEX_LD-20120431',\n",
       " 'INEX_LD-20120511',\n",
       " 'INEX_LD-20120512',\n",
       " 'INEX_LD-20120521',\n",
       " 'INEX_LD-20120522',\n",
       " 'INEX_LD-20120531',\n",
       " 'INEX_LD-20120532',\n",
       " 'INEX_LD-2009022',\n",
       " 'INEX_LD-2009039',\n",
       " 'INEX_LD-2009053',\n",
       " 'INEX_LD-2009061',\n",
       " 'INEX_LD-2009062',\n",
       " 'INEX_LD-2009063',\n",
       " 'INEX_LD-2009074',\n",
       " 'INEX_LD-2009115',\n",
       " 'INEX_LD-2010004',\n",
       " 'INEX_LD-2010014',\n",
       " 'INEX_LD-2010019',\n",
       " 'INEX_LD-2010020',\n",
       " 'INEX_LD-2010037',\n",
       " 'INEX_LD-2010043',\n",
       " 'INEX_LD-2010057',\n",
       " 'INEX_LD-2010069',\n",
       " 'INEX_LD-2010100',\n",
       " 'INEX_LD-2010106',\n",
       " 'INEX_LD-2012301',\n",
       " 'INEX_LD-2012303',\n",
       " 'INEX_LD-2012305',\n",
       " 'INEX_LD-2012309',\n",
       " 'INEX_LD-2012311',\n",
       " 'INEX_LD-2012313',\n",
       " 'INEX_LD-2012315',\n",
       " 'INEX_LD-2012317',\n",
       " 'INEX_LD-2012318',\n",
       " 'INEX_LD-2012319',\n",
       " 'INEX_LD-2012321',\n",
       " 'INEX_LD-2012323',\n",
       " 'INEX_LD-2012325',\n",
       " 'INEX_LD-2012327',\n",
       " 'INEX_LD-2012329',\n",
       " 'INEX_LD-2012331',\n",
       " 'INEX_LD-2012333',\n",
       " 'INEX_LD-2012335',\n",
       " 'INEX_LD-2012337',\n",
       " 'INEX_LD-2012339',\n",
       " 'INEX_LD-2012341',\n",
       " 'INEX_LD-2012345',\n",
       " 'INEX_LD-2012349',\n",
       " 'INEX_LD-2012353',\n",
       " 'INEX_LD-2012354',\n",
       " 'INEX_LD-2012355',\n",
       " 'INEX_LD-2012357',\n",
       " 'INEX_LD-2012359',\n",
       " 'INEX_LD-2012361',\n",
       " 'INEX_LD-2012365',\n",
       " 'INEX_LD-2012367',\n",
       " 'INEX_LD-2012369',\n",
       " 'INEX_LD-2012371',\n",
       " 'INEX_LD-2012372',\n",
       " 'INEX_LD-2012373',\n",
       " 'INEX_LD-2012377',\n",
       " 'INEX_LD-2012381',\n",
       " 'INEX_LD-2012383',\n",
       " 'INEX_LD-2012385',\n",
       " 'INEX_LD-2012387',\n",
       " 'INEX_LD-2012389',\n",
       " 'INEX_LD-2012390',\n",
       " 'INEX_XER-60',\n",
       " 'INEX_XER-62',\n",
       " 'INEX_XER-63',\n",
       " 'INEX_XER-64',\n",
       " 'INEX_XER-65',\n",
       " 'INEX_XER-67',\n",
       " 'INEX_XER-72',\n",
       " 'INEX_XER-74',\n",
       " 'INEX_XER-79',\n",
       " 'INEX_XER-81',\n",
       " 'INEX_XER-86',\n",
       " 'INEX_XER-87',\n",
       " 'INEX_XER-88',\n",
       " 'INEX_XER-91',\n",
       " 'INEX_XER-94',\n",
       " 'INEX_XER-95',\n",
       " 'INEX_XER-96',\n",
       " 'INEX_XER-98',\n",
       " 'INEX_XER-99',\n",
       " 'INEX_XER-106',\n",
       " 'INEX_XER-108',\n",
       " 'INEX_XER-109',\n",
       " 'INEX_XER-110',\n",
       " 'INEX_XER-113',\n",
       " 'INEX_XER-114',\n",
       " 'INEX_XER-115',\n",
       " 'INEX_XER-116',\n",
       " 'INEX_XER-117',\n",
       " 'INEX_XER-118',\n",
       " 'INEX_XER-119',\n",
       " 'INEX_XER-121',\n",
       " 'INEX_XER-122',\n",
       " 'INEX_XER-123',\n",
       " 'INEX_XER-124',\n",
       " 'INEX_XER-127',\n",
       " 'INEX_XER-128',\n",
       " 'INEX_XER-129',\n",
       " 'INEX_XER-130',\n",
       " 'INEX_XER-132',\n",
       " 'INEX_XER-133',\n",
       " 'INEX_XER-134',\n",
       " 'INEX_XER-135',\n",
       " 'INEX_XER-136',\n",
       " 'INEX_XER-138',\n",
       " 'INEX_XER-139',\n",
       " 'INEX_XER-140',\n",
       " 'INEX_XER-141',\n",
       " 'INEX_XER-143',\n",
       " 'INEX_XER-144',\n",
       " 'INEX_XER-147',\n",
       " 'QALD2_te-1',\n",
       " 'QALD2_te-2',\n",
       " 'QALD2_te-3',\n",
       " 'QALD2_te-5',\n",
       " 'QALD2_te-6',\n",
       " 'QALD2_te-8',\n",
       " 'QALD2_te-9',\n",
       " 'QALD2_te-11',\n",
       " 'QALD2_te-12',\n",
       " 'QALD2_te-13',\n",
       " 'QALD2_te-14',\n",
       " 'QALD2_te-17',\n",
       " 'QALD2_te-21',\n",
       " 'QALD2_te-22',\n",
       " 'QALD2_te-24',\n",
       " 'QALD2_te-25',\n",
       " 'QALD2_te-27',\n",
       " 'QALD2_te-28',\n",
       " 'QALD2_te-31',\n",
       " 'QALD2_te-33',\n",
       " 'QALD2_te-35',\n",
       " 'QALD2_te-39',\n",
       " 'QALD2_te-40',\n",
       " 'QALD2_te-42',\n",
       " 'QALD2_te-43',\n",
       " 'QALD2_te-44',\n",
       " 'QALD2_te-45',\n",
       " 'QALD2_te-46',\n",
       " 'QALD2_te-48',\n",
       " 'QALD2_te-49',\n",
       " 'QALD2_te-51',\n",
       " 'QALD2_te-53',\n",
       " 'QALD2_te-55',\n",
       " 'QALD2_te-57',\n",
       " 'QALD2_te-58',\n",
       " 'QALD2_te-59',\n",
       " 'QALD2_te-60',\n",
       " 'QALD2_te-63',\n",
       " 'QALD2_te-64',\n",
       " 'QALD2_te-65',\n",
       " 'QALD2_te-66',\n",
       " 'QALD2_te-67',\n",
       " 'QALD2_te-72',\n",
       " 'QALD2_te-75',\n",
       " 'QALD2_te-76',\n",
       " 'QALD2_te-77',\n",
       " 'QALD2_te-80',\n",
       " 'QALD2_te-81',\n",
       " 'QALD2_te-82',\n",
       " 'QALD2_te-84',\n",
       " 'QALD2_te-88',\n",
       " 'QALD2_te-89',\n",
       " 'QALD2_te-90',\n",
       " 'QALD2_te-91',\n",
       " 'QALD2_te-92',\n",
       " 'QALD2_te-93',\n",
       " 'QALD2_te-95',\n",
       " 'QALD2_te-97',\n",
       " 'QALD2_te-98',\n",
       " 'QALD2_te-99',\n",
       " 'QALD2_te-100',\n",
       " 'QALD2_tr-1',\n",
       " 'QALD2_tr-3',\n",
       " 'QALD2_tr-4',\n",
       " 'QALD2_tr-6',\n",
       " 'QALD2_tr-8',\n",
       " 'QALD2_tr-9',\n",
       " 'QALD2_tr-10',\n",
       " 'QALD2_tr-11',\n",
       " 'QALD2_tr-13',\n",
       " 'QALD2_tr-15',\n",
       " 'QALD2_tr-16',\n",
       " 'QALD2_tr-17',\n",
       " 'QALD2_tr-18',\n",
       " 'QALD2_tr-21',\n",
       " 'QALD2_tr-24',\n",
       " 'QALD2_tr-25',\n",
       " 'QALD2_tr-26',\n",
       " 'QALD2_tr-28',\n",
       " 'QALD2_tr-29',\n",
       " 'QALD2_tr-30',\n",
       " 'QALD2_tr-31',\n",
       " 'QALD2_tr-32',\n",
       " 'QALD2_tr-34',\n",
       " 'QALD2_tr-35',\n",
       " 'QALD2_tr-36',\n",
       " 'QALD2_tr-38',\n",
       " 'QALD2_tr-40',\n",
       " 'QALD2_tr-41',\n",
       " 'QALD2_tr-42',\n",
       " 'QALD2_tr-43',\n",
       " 'QALD2_tr-45',\n",
       " 'QALD2_tr-47',\n",
       " 'QALD2_tr-49',\n",
       " 'QALD2_tr-50',\n",
       " 'QALD2_tr-51',\n",
       " 'QALD2_tr-52',\n",
       " 'QALD2_tr-53',\n",
       " 'QALD2_tr-54',\n",
       " 'QALD2_tr-55',\n",
       " 'QALD2_tr-57',\n",
       " 'QALD2_tr-58',\n",
       " 'QALD2_tr-59',\n",
       " 'QALD2_tr-61',\n",
       " 'QALD2_tr-62',\n",
       " 'QALD2_tr-64',\n",
       " 'QALD2_tr-65',\n",
       " 'QALD2_tr-68',\n",
       " 'QALD2_tr-69',\n",
       " 'QALD2_tr-70',\n",
       " 'QALD2_tr-71',\n",
       " 'QALD2_tr-74',\n",
       " 'QALD2_tr-75',\n",
       " 'QALD2_tr-77',\n",
       " 'QALD2_tr-78',\n",
       " 'QALD2_tr-79',\n",
       " 'QALD2_tr-80',\n",
       " 'QALD2_tr-81',\n",
       " 'QALD2_tr-82',\n",
       " 'QALD2_tr-83',\n",
       " 'QALD2_tr-84',\n",
       " 'QALD2_tr-85',\n",
       " 'QALD2_tr-87',\n",
       " 'QALD2_tr-89',\n",
       " 'QALD2_tr-91',\n",
       " 'SemSearch_ES-1',\n",
       " 'SemSearch_ES-2',\n",
       " 'SemSearch_ES-3',\n",
       " 'SemSearch_ES-4',\n",
       " 'SemSearch_ES-5',\n",
       " 'SemSearch_ES-6',\n",
       " 'SemSearch_ES-7',\n",
       " 'SemSearch_ES-9',\n",
       " 'SemSearch_ES-10',\n",
       " 'SemSearch_ES-11',\n",
       " 'SemSearch_ES-13',\n",
       " 'SemSearch_ES-14',\n",
       " 'SemSearch_ES-15',\n",
       " 'SemSearch_ES-16',\n",
       " 'SemSearch_ES-17',\n",
       " 'SemSearch_ES-18',\n",
       " 'SemSearch_ES-19',\n",
       " 'SemSearch_ES-20',\n",
       " 'SemSearch_ES-21',\n",
       " 'SemSearch_ES-23',\n",
       " 'SemSearch_ES-24',\n",
       " 'SemSearch_ES-25',\n",
       " 'SemSearch_ES-26',\n",
       " 'SemSearch_ES-29',\n",
       " 'SemSearch_ES-30',\n",
       " 'SemSearch_ES-32',\n",
       " 'SemSearch_ES-33',\n",
       " 'SemSearch_ES-36',\n",
       " 'SemSearch_ES-38',\n",
       " 'SemSearch_ES-39',\n",
       " 'SemSearch_ES-41',\n",
       " 'SemSearch_ES-45',\n",
       " 'SemSearch_ES-47',\n",
       " 'SemSearch_ES-49',\n",
       " 'SemSearch_ES-50',\n",
       " 'SemSearch_ES-52',\n",
       " 'SemSearch_ES-56',\n",
       " 'SemSearch_ES-58',\n",
       " 'SemSearch_ES-59',\n",
       " 'SemSearch_ES-60',\n",
       " 'SemSearch_ES-61',\n",
       " 'SemSearch_ES-71',\n",
       " 'SemSearch_ES-72',\n",
       " 'SemSearch_ES-74',\n",
       " 'SemSearch_ES-75',\n",
       " 'SemSearch_ES-76',\n",
       " 'SemSearch_ES-77',\n",
       " 'SemSearch_ES-78',\n",
       " 'SemSearch_ES-80',\n",
       " 'SemSearch_ES-82',\n",
       " 'SemSearch_ES-83',\n",
       " 'SemSearch_ES-84',\n",
       " 'SemSearch_ES-85',\n",
       " 'SemSearch_ES-86',\n",
       " 'SemSearch_ES-88',\n",
       " 'SemSearch_ES-89',\n",
       " 'SemSearch_ES-90',\n",
       " 'SemSearch_ES-91',\n",
       " 'SemSearch_ES-95',\n",
       " 'SemSearch_ES-96',\n",
       " 'SemSearch_ES-97',\n",
       " 'SemSearch_ES-98',\n",
       " 'SemSearch_ES-100',\n",
       " 'SemSearch_ES-101',\n",
       " 'SemSearch_ES-102',\n",
       " 'SemSearch_ES-104',\n",
       " 'SemSearch_ES-106',\n",
       " 'SemSearch_ES-107',\n",
       " 'SemSearch_ES-108',\n",
       " 'SemSearch_ES-111',\n",
       " 'SemSearch_ES-114',\n",
       " 'SemSearch_ES-115',\n",
       " 'SemSearch_ES-118',\n",
       " 'SemSearch_ES-119',\n",
       " 'SemSearch_ES-120',\n",
       " 'SemSearch_ES-123',\n",
       " 'SemSearch_ES-124',\n",
       " 'SemSearch_ES-125',\n",
       " 'SemSearch_ES-127',\n",
       " 'SemSearch_ES-128',\n",
       " 'SemSearch_ES-129',\n",
       " 'SemSearch_ES-130',\n",
       " 'SemSearch_ES-132',\n",
       " 'SemSearch_ES-135',\n",
       " 'SemSearch_ES-136',\n",
       " 'SemSearch_ES-139',\n",
       " 'SemSearch_LS-1',\n",
       " 'SemSearch_LS-2',\n",
       " 'SemSearch_LS-3',\n",
       " 'SemSearch_LS-4',\n",
       " 'SemSearch_LS-6',\n",
       " 'SemSearch_LS-7',\n",
       " 'SemSearch_LS-8',\n",
       " 'SemSearch_LS-9',\n",
       " 'SemSearch_LS-10',\n",
       " 'SemSearch_LS-11',\n",
       " 'SemSearch_LS-12',\n",
       " 'SemSearch_LS-13',\n",
       " 'SemSearch_LS-14',\n",
       " 'SemSearch_LS-16',\n",
       " 'SemSearch_LS-18',\n",
       " 'SemSearch_LS-20',\n",
       " 'SemSearch_LS-21',\n",
       " 'SemSearch_LS-22',\n",
       " 'SemSearch_LS-24',\n",
       " 'SemSearch_LS-25',\n",
       " 'SemSearch_LS-26',\n",
       " 'SemSearch_LS-29',\n",
       " 'SemSearch_LS-30',\n",
       " 'SemSearch_LS-31',\n",
       " 'SemSearch_LS-32',\n",
       " 'SemSearch_LS-33',\n",
       " 'SemSearch_LS-34',\n",
       " 'SemSearch_LS-35',\n",
       " 'SemSearch_LS-36',\n",
       " 'SemSearch_LS-37',\n",
       " 'SemSearch_LS-38',\n",
       " 'SemSearch_LS-39',\n",
       " 'SemSearch_LS-41',\n",
       " 'SemSearch_LS-42',\n",
       " 'SemSearch_LS-43',\n",
       " 'SemSearch_LS-44',\n",
       " 'SemSearch_LS-46',\n",
       " 'SemSearch_LS-49',\n",
       " 'SemSearch_LS-50',\n",
       " 'TREC_Entity-1',\n",
       " 'TREC_Entity-2',\n",
       " 'TREC_Entity-4',\n",
       " 'TREC_Entity-5',\n",
       " 'TREC_Entity-6',\n",
       " 'TREC_Entity-7',\n",
       " 'TREC_Entity-9',\n",
       " 'TREC_Entity-10',\n",
       " 'TREC_Entity-11',\n",
       " 'TREC_Entity-12',\n",
       " 'TREC_Entity-14',\n",
       " 'TREC_Entity-15',\n",
       " 'TREC_Entity-16',\n",
       " 'TREC_Entity-18',\n",
       " 'TREC_Entity-19',\n",
       " 'TREC_Entity-20']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
