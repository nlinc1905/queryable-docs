name: Train model
inputs:
- {name: model_name, type: String}
- {name: model_path, type: String}
- {name: gcs_bucket, type: String}
outputs:
- {name: dummy, type: String}
implementation:
  container:
    image: google/cloud-sdk:slim
    command:
    - sh
    - -c
    - |2

      if ! [ -x "$(command -v pip)" ]; then
          python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip
      fi

      PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'sentence-transformers==2.2.2' 'kfp==1.8.22' && "$0" "$@"
    - sh
    - -ec
    - |
      program_path=$(mktemp -d)
      printf "%s" "$0" > "$program_path/ephemeral_component.py"
      python3 -m kfp.v2.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"
    - |2+

      import kfp
      from kfp.v2 import dsl
      from kfp.v2.dsl import *
      from typing import *

      def train_model(model_name: str, model_path: str, gcs_bucket: str) -> NamedTuple(
          "Outputs",
          [
              ("dummy", str),
          ],
      ):
          import logging
          import torch
          from sentence_transformers import SentenceTransformer
          from subprocess import call

          def get_logger():
              """Sets up logger"""
              logger = logging.getLogger(__name__)
              logger.setLevel(logging.INFO)
              handler = logging.StreamHandler()
              handler.setFormatter(
                  logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")
              )
              logger.addHandler(handler)
              return logger

          def save_model_to_gcs(model_to_save, local_path: str, bucket_folder_uri: str) -> None:
              """
              Saves the model locally, and then uses gsutil to copy the local directory to a gcs
              bucket folder.
              """
              # save the model locally first
              model_to_save.save(local_path)

              # copy files to bucket
              call(["gsutil", "cp", "-r", f"./${local_path}/*", f"${bucket_folder_uri}"], shell=True)

              # remove local directory
              call(["rm", "-R", f"${local_path}"], shell=True)

          logger = get_logger()
          device = 'cuda' if torch.cuda.is_available() else 'cpu'
          model = SentenceTransformer(model_name, device=device)

          if device == "cuda":
              torch.cuda.empty_cache()
          logger.info(f"Using device {device}")

          gcs_model_folder = f"{model_name.lower()}"
          gcs_model_folder_uri = f"gs://{gcs_bucket}/{gcs_model_folder}"

          # placeholder comment for future training

          # save the model to gcs
          save_model_to_gcs(
              model_to_save=model,
              local_path=model_path,
              bucket_folder_uri=gcs_model_folder_uri
          )

          # To make sure downstream tasks are dependent on this one finishing,
          # before they can begin, we will return a dummy string that downstream
          # tasks will take as input.
          dummy = "done"
          return (dummy,)

    args:
    - --executor_input
    - {executorInput: null}
    - --function_to_execute
    - train_model
